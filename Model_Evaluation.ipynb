{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### All random states are assigned to 42 for reproducible results\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_userid(num_users):\n",
    "    \"\"\"\n",
    "    pick 1 random user at random\n",
    "    Args:\n",
    "        num_users:: int\n",
    "    Returns:\n",
    "        user_id_eval:: int, user_id to evaluate\n",
    "    \"\"\"\n",
    "    user_id_eval = np.random.randint(num_users)\n",
    "    return user_id_eval\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_y_true(user_id, x_train, y_train):\n",
    "    # Stacking x_train and y_train\n",
    "    y_true_tmp = np.hstack((x_train, y_train))\n",
    "    # keep only the recommended games\n",
    "    y_true_tmp = y_true_tmp[y_true_tmp[:,-1] == 1]\n",
    "    # filtering for the user id\n",
    "    y_true = y_true_tmp[y_true_tmp[:,0] == user_id][:,1]\n",
    "    return y_true\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_games(user_id, num_games):\n",
    "    # Generate a list of all games for a specific user\n",
    "    #games = list(games_mapping.keys())\n",
    "    games = np.arange(num_games)\n",
    "    games2pred = np.reshape(games, (-1,1))\n",
    "    user_game_array_eval = np.hstack(([[user_id]] * len(games), games2pred))\n",
    "    return user_game_array_eval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_y_pred(user_games_array, K):\n",
    "    preds = model.predict(user_games_array)\n",
    "    user_games_preds = np.hstack((user_games_array, preds))\n",
    "    sorted_indices = np.argsort(-user_games_preds[:, -1])\n",
    "    y_pred = user_games_preds[sorted_indices][:K, :]\n",
    "    y_pred = y_pred[:,1].astype('int32')\n",
    "    return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_k(y_true, y_pred):\n",
    "    items_relevant_user = len(y_true)\n",
    "    rec_items_relevant = len(set(y_true).intersection(set(y_pred)))\n",
    "    recall = rec_items_relevant / items_relevant_user\n",
    "    precision = rec_items_relevant / K\n",
    "    return recall, precision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_k_avg(n_users2val, K, num_users, num_games, x_train, y_train):\n",
    "    \"\"\"\n",
    "    Evaluate Top K precision and recall\n",
    "    Args:\n",
    "        n_users2val:: int, number of users to evaluate\n",
    "        K:: int\n",
    "        num_users:: int, number of users in the test set\n",
    "        games_mapping:: dict, keys: integer (idx), values: orginal app_id_categorical\n",
    "        x_train\n",
    "        y_train\n",
    "\n",
    "    Returns:\n",
    "        avg_precision:: float, top K average precision\n",
    "        avg_recall:: float, top K average recall\n",
    "    \"\"\"\n",
    "    precision = []\n",
    "    recall = []\n",
    "    for i in range(n_users2val):\n",
    "        user_id_eval = get_random_userid(num_users)\n",
    "        y_true = get_y_true(user_id_eval, x_train, y_train)\n",
    "        user_games = get_user_games(user_id_eval, num_games)\n",
    "        y_pred = get_y_pred(user_games, K)\n",
    "        rcl, prc = eval_k(y_true, y_pred)\n",
    "        precision.append(prc)\n",
    "        recall.append(rcl)\n",
    "    avg_precision = np.mean(precision)\n",
    "    avg_recall = np.mean(recall)\n",
    "    return avg_precision, avg_recall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_hit_ratio(n_users2val, K, num_games, x_test):\n",
    "    counter = 0\n",
    "    for user_game in x_test[:n_users2val,:]:\n",
    "        user_games = get_user_games(user_game[0], num_games)\n",
    "        y_pred = get_y_pred(user_games, K)\n",
    "        if(user_game[1] in y_pred):\n",
    "            counter += 1\n",
    "    return counter / n_users2val\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
